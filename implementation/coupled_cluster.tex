\chapter{Implementation: Coupled Cluster}

The main product of this study is manifested in the \lstinline{coupled_cluster}
module for Python. This module is designed to fit together with the
\lstinline{quantum_systems} module described in the previous chapter. We have tried to 
make this module easy to extend, resulting in a framework where every solver scheme 
inherits from an abstract parent class that specifies what must be implemented in order 
to make a supplemental solver or class operational in conjunction with the rest of the 
framework.

As a beginning to this project, which we hope will continue to grow and be used, 
we have implemented several different ground state solver classes, and several
time-dependent solver classes. In order of increasing sophistication and 
elegance, we have a ground state- and a time-dependent solver for both the coupled cluster
method
with double excitations (CCD), the coupled cluster method with singles- and double 
excitations (CCSD), and for the orbital-adaptive coupled cluster method with double
excitations (OACCD). The time-dependent solvers within a particular categor are 
dependent on its ground state counterpart, but the ground state solvers can be used
independently.

The \lstinline{coupled_cluster} module can be install from github via \lstinline{pip}
by the following command,
\begin{lstlisting}[language=bash]
pip install git+https://github.com/Schoyen/coupled-cluster.git
\end{lstlisting}
If one prefers, the same task can be accomplished by the following commands,
\begin{lstlisting}[language=bash]
git clone https://github.com/Schoyen/coupled-cluster.git
cd coupled-cluster
pip install .
\end{lstlisting}
We have supplied environment specifications for \lstinline{conda}, with requirement 
specifications for the convenience of the user. Assuming the git repository is cloned 
properly,
\begin{lstlisting}[language=bash]
conda environment create -f environment.yml
\end{lstlisting}
Activate the environment with,
\begin{lstlisting}[language=bash]
conda activate cc
\end{lstlisting}
In the future, we hope that full documentation can be found on
\url{www.coupled-cluster.com}.

\section{Ground State Computations}

    All ground state solver within the \lstinline{coupled_cluster} module are built 
    as sub-classes of the abstract base class \lstinline{CoupledCluter}. The most
    important method of this class is the \lstinline{compute_ground_state()} method.
    This method in turn calls the \lstinline{iterate_t_amplitudes()} and 
    \lstinline{iterate_l_amplitudes()} successively. 

    \input{implementation/doc/coupled_cluster.tex}

    As we have outlined in 
    \autoref{ch:coupled_cluster_theory}, the $\tau$ amplitudes are only dependent on 
    $\tau$, while the $\lambda$ amplitudes are dependent on both $\tau$ and $\lambda$.
    Therefore, the $\tau$ amplitude equation iterative solver
    \lstinline{iterate_t_amplitudes()} is called first, and the $\lambda$ amplitude
    equation solver is called second.
    The most important section of the \lstinline{compute_l_amplitudes()} method 
    is the following
    \begin{python}
    for i in range(max_iterations):
    self.compute_l_amplitudes()
    residuals = self.compute_l_residuals()

    if self.verbose:
        print(f"Iteration: {i}\tResiduals (l): {residuals}")

    if all(res < tol for res in residuals):
        break

    assert i < (
        max_iterations - 1
    ), f"The l amplitudes did not converge. Last residual: {residuals}" 
    \end{python}
    The equivalent section in the \lstinline{compute_t_amplitudes()} method is nearly
    identical.
    The \lstinline{CoupledCluster} class is supposed to provide a framework for which 
    to implement various coupled cluster ground state solver classes. It therefore
    has several abstract classes that such subclasses need to implement and overwrite.
    The most important of these are the methods \lstinline{compute_t_amplitudes} 
    and \lstinline{compute_l_amplitudes}, which are supposed to contain the evaluation 
    of amplitude equations for a given coupled cluster truncation and scheme. 

    With the hope that the functunality of the rest of the methods can be inferred from 
    name, and with the goal of brevity we proceed to a study of the simplest 
    ground state coupled cluster solver, namely CCD, implemented in the 
    \lstinline{CoupledClusterDoubles} class.
   
    Starting from construction, the \lstinline{CoupledClusterDoubles} class passes 
    the system, defined through a \lstinline{QuantumSystem} object to the 
    parent class constructor, along with any keyword arguments, such as turning 
    on verbosity, mixer type to us and what matrix library to apply. The
    \lstinline{QuantumSystem} class will contain all the information necessary to 
    set up the system, i.e. construct a one-body matrix, fock matrix and two-body 
    matrix. These will be used to set up empty arrays for the $\tau$ and $\lambda$ 
    amplitudes. The \lstinline{comput_initial_guess} is called lastly in the 
    constructor, computing the inital guess of the double-excited amplitudes as 
    \begin{equation}
        \label{eq:ccd_inital_guess}
        \tau^{(0)} = \frac{u^{ab}_{ij}}{D^{ab}_{ij}},
    \end{equation}
    where $u$ is the two-body operator and
    $D^{ab}_{ij} = f^a_a + f^b_b - f^i_i - f^j_j$,
    where $f$ is the Fock operator.
    
    In the \lstinline{CoupledClusterDobles} class specification one would
    notice that it has implementations of all the abstract methods 
    from the \lstinline{CoupledCluster} abstract class. The reason for the existence 
    of the class, the \lstinline{compute_ground_state()} method, is inherited from the 
    parent class, and does the same thing as described above - calling 
    \lstinline{iterate_t_amplitudes()} and \lstinline{iterate_l_amplitudes()}. These 
    methods alos excist as members of \lstinline{CoupledClusterDoubles}, but are excluded 
    from the class specification for sake of brevity. It is 
    possible to pass arguments to the the two iterator methods; one list for each iteration
    method, or as keywords.
    One can also pass arguments 
    to the mixer through the \lstinline{compute_ground_state_method()}. 
    An overview of mixing applied to iterative solvers is given in the next 
    section.

    The important part of the specific coupled cluster scheme solver is contained in the two 
    methods \lstinline{compute_t_amplitudes()} and \lstinline{compute_l_amplitudes()}.
    These functions evaluate the entire coupled cluster doubles amplitude equations.
    The computation of each term (diagram) in the amplitude equation is done in separate functions,
    as calls to \lstinline{numpy.tensordot()}, for a total of ten terms for the 
    $\tau$ amplitude equation in the coupled cluster doubles method including 
    permutation operators:
    \begin{equation}
        \label{eq:ccd_tau}
        \begin{aligned}
        0 =& u^{ab}_{ij} + f^b_c \tau^{ac}_{ij}P(ab) 
            - f^k_j \tau^{ab}_{ik}P(ij)
            + \frac{1}{4} \tau^{ac}_{ij} \tau^{ab}_{mn}u^{mn}_{cd} 
            + \frac{1}{2} \tau^{cd}_{ij}u^{ab}_{cd}
            + \frac{1}{2} \tau^{cd}_{jm} \tau^{ab}_{in} u^{mn}_{cd}P(ij) \\
            &\ - \frac{1}{2} \tau^{ac}_{nm} \tau^{bd}_{ij} u^{nm}_{cd}P(ab)
            + \tau^{ac}_{im} \tau^{bd}_{jn}u^{mn}_{cd}P(ij)
            + \tau^{ac}_{im}u^{bm}_{jc}P(ab)P(ij)
            + \frac{1}{2} \tau^{ab}_{mn}u^{mn}_{ij}.
        \end{aligned}
    \end{equation}

    \input{implementation/doc/ccd.tex}
   
    THIS IS NOT CORRECT WHEN INCLUDING LAMBDA..
    The initial guess in equation \autoref{eq:ccd_inital_guess} is terms 2 and 3
    from \autoref{eq:ccd_tau}. These terms also form the basis of the iterative scheme,
    if we move them to the left of the equal sign in \autoref{eq:ccd_tau}, 
    \begin{equation}
        D^{ab}_{ij} \tau^{ab}_{ij} = g(u, \tau),
    \end{equation}
    where $g(u, \tau)$ now consists of the rest of the doubles amplitude equation, our 
    recursion relation can be written
    \begin{equation}
        t^{(k+1)} = \frac{g(u,\tau^{(k)})}{D^{ab}_{ij}}.
    \end{equation}
    
    An example of a computation of one term from \autoref{eq:ccd_tau} is,
    \begin{python}
    def add_d2e_t(u, t, o, v, out, np):
        term = np.tensordot(t, u[o, v, v, o], axes=((1, 3), (2, 0))).transpose(
            0, 2, 1, 3
        )
        term -= term.swapaxes(0, 1)
        term -= term.swapaxes(2, 3)
        out += term
    \end{python}
    This function particular computes the $D_{2e}$ diagram\footnote{After the labelling from 
    \autoref{ch:coupled_cluster_theory} and Shavitt \& Bartlett\cite{shavitt2009many}}.

    Most of the rest of the methods in the \lstinline{CoupledClusterDoubles} class are there 
    for the use of other methods, or for extracting observables. Moving to the next logical 
    coupled cluster solver scheme; the coupled cluster method with single- and double 
    excitations is now a matter of taking into account the extra computations needed in 
    this scheme, for each method in the abstract base clase \lstinline{CoupledCluster}. 
    There are indeed many more computations, but the code will structurally be the same. 
    The class specification for \lstinline{CoupledClusterSinglesDoubles} is therefore 
    given here without specification of the methods as they are excactly the same. For testing 
    purposes, the \lstinline{CoupledClusterSingelsDoubles} class have the possibility 
    to only include double excitation at construction.

    \input{implementation/doc/ccsd.tex}

    The algorithm applied when computing the ground state in the orbital-adaptive sphere 
    is the nonorthogonal orbital-optimised coupled cluster (NOCC) method, developed by 
    Myhre\cite{myhre2018demonstrating}. The NOCC scheme is shown to converge towards full
    configuration interaction. Since the \lstinline{OACCD} class is acutally applying 
    NOCC it can be perceived as a misnomer, but as of yet there exist no ground state 
    equivalent of the time-dependent 
    orbital-adaptive coupled cluster (OACC) method. Such a method is in development, and there
    is strong indication that NOCC would be equivalent to a OACC ground state solver. What is 
    more, NOCC does vary the orbitals as well as iterate over amplitude, and we have therefore 
    opted to call it OACC.

    \input{implementation/doc/oaccd.tex}

    Our implementation of the NOCC ground state solver is inderited from code written by Rolf Myhre and 
    adapted to our 
    framework. We supply a brief overview of the algorithm here. The starting point for the 
    NOCC model is the bivariational Lagrangian
    \begin{equation}
        \label{eq:nocc_lagrangian}
        \mathscr{L} = \mel*{\tilde{\Psi}}{\hat{H}}{\Psi} \\
            = \mel*{\tilde{\phi}}
                {
                (1 + \Lambda) e^{-\hat{T}}e^{-\kappa}\hat{H}e^{\kappa}e^{\hat{T}}
                }{\phi}
    \end{equation}
    which is very similar to the coupled cluster Lagrangian (\autoref{eq:cc_energy_lagrangian}),
    except for a biorthogonal basis and a transformation of the Hamiltonian, defined 
    as follows
    \begin{equation}
        \begin{aligned}
            \tilde{c}_p^\dagger &= e^{-\kappa}\hat{c}_p^\dagger e^\kappa \\
            c_p &= e^{-\kappa} \hat{c}_p^\dagger e^\kappa \\
            \ket{\phi} &= e^{-\kappa}\ket*{\hat{\phi}}
        \end{aligned}
    \end{equation}
    where the orthogonal reference creation- and annihilation operators marked with a hat
    ($\hat{\ }$), as is the reference state function. We require that $\kappa$ is antihermitian,
    \begin{equation}
        \kappa = \sum_{pq} \kappa_{pq}c^\dagger_p c_q, \quad \kappa^\dagger = -\kappa.
    \end{equation}
    Moreover, we split $\kappa$ into excitations and relaxations (up and down),
    \begin{equation}
        \label{eq:agg_kappa}
        \kappa = \sum_{ai} \kappa^u_{ai}c^\dagger_a \tilde{a}_i
            + \kappa^d_{ia} c^\dagger_i \tilde{c}_a
            = \sum_{ai} \kappa^u_{ai} X_ai + \kappa^d_{ia} \tilde{X}^\dagger_{ia}.
    \end{equation} 
    
    As in any many-body formulation that includes a Lagrangian, we would like to compute 
    the first-order conditions of the Lagrangian, in order to derive what would be the 
    NOCC equation. The problem with this is that the result would be some extremely 
    lengthy expressions, because $\kappa$ does not commute with $\hat{T}$ or $\Lambda$.
    Therefore, we express the NOCC equations with an optimized basis where $\kappa=0$,
    where a solution would correspond to a stationary point of the Schrödinger equation.
    This is the same as expanding the exponentials in $\kappa$ and keeping only zero-order 
    terms. This trick leads to an algorithm which iterates between orbital transformations 
    and amplitudes until self-consistency.

    At a particular stationary point the differential of the Lagrangian
    (\autoref{eq:nocc_lagrangian}) must be zero with respect to the four sets of 
    parameters $\{\tau\}$, $\{\lambda\}$, $\{\kappa^u\}$ and $\{\kappa^d\}$, giving
    us four sets of equations,
    \begin{align}
        \frac{\partial \mathscr{L}}{\partial \lambda_{\mu_n}}
            &= \mel*{\tilde{\phi}}
            {\tilde{X}_{\mu_n} e^{-\hat{T}}\hat{H}e^{\hat{T}}}
            {\phi}, \\
        \frac{\partial \mathscr{L}}{\partial \tau_{\mu_n}}
            &= \mel*{\tilde{\phi}}
            {(1 + \Lambda)e^{-\hat{T}}[\hat{H}, X_{\mu_n}]e^{\hat{T}}}
            {\phi}, \\
        \frac{\partial \mathscr{L}}{\partial \kappa^u_{\mu_1}}
            &= \mel*{\tilde{\phi}}
            {(1 + \Lambda)e^{-\hat{T}}[\hat{H}, X_{\mu_1}]e^{\hat{T}}}
            {\phi}, \\
        \frac{\partial \mathscr{L}}{\partial \kappa^d_{\mu_1}}
            &= \mel*{\tilde{\phi}}
            {(1 + \Lambda)e^{-\hat{T}}[\hat{H}, \tilde{X}_{\mu_1}]e^{\hat{T}}}
            {\phi}.
    \end{align}

    We are now ready to outline the full algorithm of the 
    \lstinline{compute\_ground\_state()} in what we have called the \lstinline{OACCD}.
    The method is iterating over the the norm of $\kappa^u$ and $\kappa^d$, called the 
    residuals of $\kappa$, until consistency compared to a tolerance value us achieved. 
    For each such iteration, iteration over the $\tau$ and $\lambda$ double excitation
    amplitudes is performed, but at a much less strict tolarance value than under the 
    \lstinline{CoupledClusterDoubles} scheme. After the iteration over $\tau$ and $\lambda$ 
    is achieved, the values for $\kappa^u$ and $\kappa^d$ are recalculated, in order to 
    compute the aggragate $\kappa$ (\autoref{eq:agg_kappa}), 
    which in turn can be used to transform the orbitals,
    \begin{equation*}
        \begin{gathered}
            h^{(k + 1)} = e^{-\kappa} h^{(k)} e^{\kappa}, \\
            (u^{pq}_{rs})^{(k + 1)}
            = (e^{-\kappa})^p_a (e^{-\kappa})^q_b 
                (u^{ab}_{cd})^{(k)}
            (e^{\kappa})^d_s (e^{\kappa})^c_r,
        \end{gathered}
    \end{equation*}
    which (in addition to being written with incomprehensible notation) is used to compute 
    a new Fock operator. The resulting rotation of the orbitals will aid in better 
    convergence towards the ground state. FLOW CHART??
    
\subsection{Mixing}

    Iterative many-body methods are prone to convergence problems for certain configurations.
    This would be doubly important since we have moved to a variational description 
    of coupled cluster theory,
    where generalisations of the variational theory dictate inifitesimal variations, which 
    is not always feasible to implement.
    Moreover, an iterative optimisation scheme may not always converge properly at all. 
    Luckily, there exists numerous techniques both for controlling and acceleration 
    convergence.

    The simplest way to ``massage'' convergence out of the coupled cluster ground state methods
    to use a dampening, where one would include a part of the result from the previous 
    iteration, here applied to the $\tau$ amplitudes,
    \begin{equation}
        \bar{\tau}^{(k+1)} = (1 - \theta)\tau^{(k+1)} + \theta\tau^{(k)},
    \end{equation}
    where $\tau^{(k+1)}$ is the current result from evaluating the amplitude equations, 
    and $\tau^{(k)}$ is the previous value. Choosing $\theta \in [0,1]$ will tune how
    much of the previous amplitude to include in the new state. The idea is to allow for 
    a more gentle transition between the iterations. We have implemented this 
    very simple mixing scheme in the \lstinline{AlphaMixer} class, which also serves as 
    a base class for further mixer implementations.

    \input{implementation/doc/mixer_alpha.tex}

    A more sophisticated method to aid in convergence, and perhaps the most popular,
    is by performing a direct inversion of iterative subspace (DIIS). The DIIS method 
    is built to accelerate the quasi-Newton method, an we will necesarily outline the 
    quasi-Newton before we examine DIIS, which is explained in Helgaker et 
    al.\cite{helgaker2014molecular}.

    The commutator of Fock operator with the cluster operator is generally
    \begin{equation}
        \label{eq:fock_cluster_commutator}
        [\hat{f}, \hat{T}] = \sum_\mu D_\mu \tau_\mu X_\mu,
    \end{equation}
    where $\epsilon_\mu$ is the sum of unoccupied energies minus sum of all 
    occupied energies, i.e. $D^{ab}_{ij} = \epsilon_a  + \epsilon_b - \epsilon_i - \epsilon_j$,
    $\tau_\mu$ is the amplitude of a particular excitation, and $X_\mu$ is an excitation 
    operator. For CCD \autoref{eq:fock_cluster_commutator} becomes,
    \begin{equation}
        [\hat{f}, \hat{T}_2] = D^{ab}_{ij} \tau^{ab}_{ij} c^\dagger_a c^\dagger_b c_i c_j.
    \end{equation}
    This allows us to write the coupled cluster vector function $\Omega^{(0)}_\mu$,
    and its Jacobian $\Omega^{(1)}_{\mu\nu}$ of the $n$th iteration in the form 
    \begin{align}
        \label{eq:vector_function_diis}
        \Omega^{(0)}_\mu &= D_\mu \tau^{(n)}_\mu 
            + \mel{\Phi_\mu}
            {e^{-\hat{T}^{(n)}} \hat{U} e^{\hat{T}^{(n)}}}
            {\Phi_0} \\
        \label{eq:jacobian_diis}
        \Omega^{(1)}_{\mu\nu} &= D_\mu\delta_{\mu\nu} 
            + \mel{\Phi_\mu}
            {e^{-\hat{T}^{(n)}} [\hat{U}, X^\nu] e^{\hat{T}^{(n)}}}
            {\Phi_0}
    \end{align}
    which are very similar to the coupled cluster energy and amplitude equations, but 
    the matrix element contains just $\hat{U}$, the fluctuation potential, instead of 
    the entire Hamiltonian $\hat{H} = \hat{F} + \hat{U}$. HERE I AM BEING INCONSISTENT
    WITH MY NOTATION AGAIN.

    The Jacobian constists onluy of a diagonal part, involving differences of the 
    orbital energies, and a nondiagonal part, containing the fluctuation potential.
    The trick from \emph{Newton's} method is to expand the vector functions around 
    the set of amplitudes of the current iteration $\tau^{(n)}$,
    \begin{equation}
        \Omega(\tau^{(n)} + \Delta\tau) = \Omega^{(0)}(\tau^{(n)})
            + \Omega^{(1)}(\tau^{(n)})\Delta \tau + \dots,
    \end{equation}
    which leads to a recursion relation be neglecting terms that are nonlinear in
    $\Delta \tau$,
    \begin{equation}
        \Omega^{(1)}(\tau^{(n)})\Delta \tau^{(n)} = - \Omega^{(0)}(\tau^{(n)}).
    \end{equation}
    By inserting \autoref{eq:vector_function_diis} and \autoref{eq:jacobian_diis} 
    we get the \emph{quasi-Newton} equations for the optimisation of the 
    coupled-cluster wavefunction,
    \begin{equation}
        \label{eq:quasi_newton}
        \Delta \tau^{(n)}_\mu = - \frac{\Omega^{(0)}_\mu(\tau^{(n)})}{D_\mu}
    \end{equation}
    The quasi-Newton method is fairly robust, but the convergence may be improved 
    significantly by introducing DIIS.

    In the DIIS framework\cite{pulay1980convergence}, the new amplitudes 
    $\tau^{(n+1)}$ are obtained by a linear interpolation among the previous 
    estimates of the amplitudes,
    \begin{equation}
        \tau^{(n+1)} = \sum_{k+1}^n w_k(\tau^{(k)} + \Delta\tau^{(k)}),
    \end{equation}
    where $\Delta\tau^{(k)}$ are obtained from \autoref{eq:quasi_newton}, and 
    the interpolations weights sum to unity,
    \begin{equation*}
        \label{eq:diis_weights_sum}
        \sum_{k=1}^n w_k = 1.
    \end{equation*}
    To determine the DIIS weights, we associate each set of amplitudes $\tau^{(k)}$ 
    with an error vector. We use the scaled vector function $\Delta\tau^{(k)}$ as 
    error vector and determine the interpolation coefficients by minimising the norm of 
    the averaged vector
    \begin{equation}
        \Delta \tau^{\text{ave}} = \sum_{k=1}^n w_k \Delta \tau^{(k)}
    \end{equation}
    subject to \autoref{eq:diis_weights_sum}.

    We have implemented the DIIS acceleration of the quasi-Newton method in the class 
    \lstinline{DIIS}. This class inherits from the \lstinline{AlphaMixer} class and
    would function in its place. The \lstinline{DIIS} class allows one to pick 
    how many vectors to store and compute a linear interpolation of, with a default 
    value of $10$ vectors.

    \input{implementation/doc/diis.tex}

\section{[UNFINISHED] Time Development}

    Simlarly to the rest of the \lstinline{coupled_cluster} module, the portion relating
    to time development begins with an abstract base class,
    \lstinline{TimeDependentCoupledCluster}
    functioning as an interface for the rest of the classes. At construction, the 
    \lstinline{TimeDependentCoupledCluster} class is passed an affiliated 
    ground state solver in the form of a \lstinline{CoupledCluster} object, a 
    \lstinline{QuantumSystems} object and an \lstinline{Integrator} object. All these 
    are necessary in order to compute a time-development. The starting point of a 
    time development is a system at it's ground state, necessitating the specification 
    of a system and a ground state solver. The system is developed in time by solving 
    the equations of motion with a numerical integrator. We will consider 
    integrators separately in the next section.

    Inclusion of a \lstinline{CoupledCluster} object in the 
    \lstinline{TimeDependentCoupledCluster} class allows one to call the 
    \lstinline{compute_ground_state()} from this object, and it is included as a 
    wrapper. Severak other methods are included from the ground state realm, like 
    the methods for particle density computations. 

    The bare minimum that a time-dependent coupled cluster scheme needs to implement 
    in order to function is the methods \lstinline{rhs_t_amplitudes()} and 
    \lstinline{rhs_l_amplitudes()}, which should return the right-hand side of 
    the amplitude equations. These methods should be integrated as generators, to make 
    it possible to iterate over them, and should yield the amplitudes in order of 
    increasing excitation level.

    \input{implementation/doc/tdcc.tex}

    Arguably the most important method in the \lstinline{TimeDependentCoupledCluster}
    abstract base class is the \lstinline{solve(time_steps)} method. For the array 
    of time steps supplied, this method propagates with the integrator member of the 
    class for all amplitudes. This method remains the same for all time-propagation 
    schemes, and is therefore implemented in the base class for inheritance in 
    sub-classes. This method in full is
    \begin{python}
    def solve(self, time_points, timestep_tol=1e-8):
        n = len(time_points)

        for i in range(n - 1):
            dt = time_points[i + 1] - time_points[i]
            amp_vec = self.integrator.step(
                self._amplitudes.asarray(), time_points[i], dt
            )

            self._amplitudes = type(self._amplitudes).from_array(
                self._amplitudes, amp_vec
            )

            if abs(self.last_timestep - (time_points[i] + dt)) > timestep_tol:
                self.update_hamiltonian(time_points[i] + dt, self._amplitudes)
                self.last_timestep = time_points[i] + dt

            yield self._amplitudes
    \end{python}
    We see that after the integrator is advanced one step in time, returning an amplitude 
    vector. This amplitude object is stored as a member of the class by use of the 
    \lstinline{from_array()} method from the \lstinline{AmplitudeContainer} class,
    after which the  
    Hamiltonian of the system is updated if enough time has passed.

    \noindent -------- \\
    SECTION ON IMPLEMENTATION OF \lstinline{__call__} HERE? \\
    \noindent -------- 

    We have implemented both a time-dependent CCD (TDCCD) solver and a time-dependent CCSD
    (TDCCSD)
    solver. For the sake of brevity, we present only the TDCCSD here. 
    The \lstinline{TDCCSD} class, a sub-class of \lstinline{TimeDependentCoupledCluster},
    inheriting all methods from this super-class. It accepts the same parameter as the super-class, except the 
    parameter that defines the ground state solver to be used - the \lstinline{CoupledCluster}
    class implementation. The ground state solver is already decided by the level of 
    excitation for the computation at hand. All parameters are passed to the constructor 
    in the parent class.

    The \lstinline{solve()} method will have the exact same functionality as in the parent class,
    but since the \lstinline{TDCCSD} contains amplitudes and everything else needed to 
    solve the equations of motions in a singles and doubles trunctation, it will now yield a 
    \lstinline{Generator} object 
    containing amplitudes that are developed in time. Any observable can be extracted during 
    an iteration over this \lstinline{Generator} object. We have implemeted several methods that 
    can be useful in extracting information about the state of the time-developed system,
    for instance \lstinline{compute_time_dependent_overlap} which computes the 
    probability of the system being in the ground state, and \lstinline{compute_energy} 
    which computes the energy of the system in the current time-dependent state.
    The ground state probability, i.e. \lstinline{compute_time_dependent_overlap}, is 
    given by a general time-dependent auto-correlation function,
    \begin{equation}
        \label{eq:td_autocorr_1}
        A(t', t) \equiv \braket{S(t')}{S(t)}.
    \end{equation}
    Because coupled cluster theory is not variational in the usual sense it is necessary to 
    define a general state vector as combination of both $\ket{\Psi}$ and $\bra*{\tilde{\Psi}}$,
    \begin{equation}
        \ket{S} = \frac{1}{\sqrt{2}} \begin{pmatrix}
            \ket{\Psi} \\ \ket*{\tilde{\Psi}}
        \end{pmatrix}
    \end{equation}
    which makes the time-dependent auto-correlation function (\autoref{eq:td_autocorr_1}),
    \begin{equation}
        A(t', t) = \frac{1}{2} 
        \left( \braket*{\tilde{\Psi}(t')}{\Psi(t)} 
            +  \braket*{\Psi(t')}{\tilde{\Psi}(t)}  \right)
    \end{equation}
    according to the definitions of the \emph{indefinite} innerproduct by Petersen and 
    Kvaal\cite{pedersen2019symplectic}. Here we would set $t'=0$, because we are
    interested in the ground state overlap, translating to the state before developement 
    in time.

    \input{implementation/doc/tdccsd.tex}

    Within our truncation to includ only single- and double escitations,
    an inner product of two state vectors, in the normal coupled cluster scheme
    with static orbitals, can be computed in the following manner
    \begin{equation}
        \begin{aligned}
            \braket{\Psi'}{\Psi} 
            =& \mel{\Phi}
            {
                (1 + \Lambda)e^{-\hat{T}'} e^{\hat{T}}
            }
            {\Phi} \\
            =&
            \mel{\Phi}{
            (1 + \Lambda_1 + \Lambda_2)
            (1 - \hat{T}'_1 - \hat{T}'_2 + \frac{1}{2}\hat{T}'^2_1) 
            (1 + \hat{T}_1 + \hat{T}_2 + \frac{1}{2}\hat{T}^2_1)
            }{\Phi} \\
            =& \braket{\Phi} - \mel{\Phi}{\Lambda_1\hat{T}'_1}{\Phi} 
                + \mel{\Phi}{\Lambda_1\hat{T}'_1}{\Phi}
                - \mel{\Phi}{\Lambda_2\hat{T}'_1\hat{T}_1}{\Phi}
                - \mel{\Phi}{\Lambda_2\hat{T}'_2}{\Phi} \\
            \ & + \mel{\Phi}{\Lambda_2\hat{T}_2}{\Phi}
                + \frac{1}{2}\mel{\Phi}{\Lambda_2\hat{T}'_1\hat{T}'_1}{\Phi}
                + \frac{1}{2}\mel{\Phi}{\Lambda_2\hat{T}_1\hat{T}_1}{\Phi},
        \end{aligned}
    \end{equation}
    where we have ignored terms that would give a zero-contribution.
    Evaluating the remainding terms can be done with your 
    favourite method. Here is an example using Wick's theorem,
    \begin{equation}
        \begin{aligned}
            \mel{\Phi}{\Lambda_2\hat{T}_2}{\Phi} 
            &= \mel{\Phi} 
            {
            \sum_{abij} \frac{1}{4}\lambda^{ij}_{ab}
                \{\hat{i}^\dagger \hat{a} \hat{j}^\dagger \hat{b} \}
            \sum_{cdkl} \frac{1}{4}\tau^{cd}_{kl}
                \{\hat{c}^\dagger \hat{k} \hat{d}^\dagger \hat{l} \}           
            } 
            {\Phi} \\
            &= \mel{\Phi} 
            {
            \sum_{\substack{abcd\\ijkl}} \frac{1}{16}\lambda^{ij}_{ab} \tau^{cd}_{kl}
                \wick{
                \{\c1{\hat{i}^\dagger} \c2{\hat{a}} \c3{\hat{j}^\dagger} \c4{\hat{b}} \}
                \{\c2{\hat{c}^\dagger} \c1{\hat{k}} \c4{\hat{d}^\dagger} \c3{\hat{l}} \}
                } 
            } 
            {\Phi}  + \text{three more equivalent contractions} \\
            &= 
            \frac{1}{4} \mel{\Phi} 
            {
                \sum_{\substack{abcd \\ ijkl}} \lambda^{ij}_{ab} \tau^{cd}_{kl} 
                \delta_{ac} 
                \delta_{bd}
                \delta_{ik} 
                \delta_{jl}
            } {\Phi}
            = \frac{1}{4} \sum_{abij} \lambda^{ij}_{ab} \tau^{ab}_{ij}.
        \end{aligned}
    \end{equation}

    The entirity of the \lstinline{compute_time_dependent_overlap_method()} consists of
    similar computations,
    \begin{python}
    def compute_time_dependent_overlap():
        np = self.np
        t_0, t_1, t_2, l_1, l_2 = self._amplitudes.unpack()
        t_1_0, t_2_0 = self.cc.t_1, self.cc.t_2 
        l_1_0, l_2_0 = self.cc.l_1, self.cc.l_2

        psi_t_0 = 1
        psi_t_0 += np.einsum("ia, ai ->", l_1, t_1_0)
        psi_t_0 -= np.einsum("ia, ai ->", l_1, t_1)
        psi_t_0 += 0.25 * np.einsum("ijab, abij ->", l_2, t_2_0)
        psi_t_0 -= 0.5 * np.einsum("ijab, aj, bi ->", l_2, t_1_0, t_1_0)
        psi_t_0 -= np.einsum("ijab, ai, bj ->", l_2, t_1, t_1_0)
        psi_t_0 -= 0.5 * np.einsum("ijab, aj, bi ->", l_2, t_1, t_1)
        psi_t_0 -= 0.25 * np.einsum("ijab, abij ->", l_2, t_2)
    
        psi_0_t = 1
        psi_0_t += np.einsum("ia, ai ->", l_1_0, t_1)
        psi_0_t -= np.einsum("ia, ai ->", l_1_0, t_1_0)
        psi_0_t += 0.25 * np.einsum("ijab, abij ->", l_2_0, t_2)
        psi_0_t -= 0.5 * np.einsum("ijab, aj, bi ->", l_2_0, t_1_0, t_1_0)
        psi_0_t -= np.einsum("ijab, ai, bj ->", l_2_0, t_1, t_1_0)
        psi_0_t -= 0.5 * np.einsum("ijab, aj, bi ->", l_2_0, t_1, t_1)
        psi_0_t -= 0.25 * np.einsum("ijab, abij ->", l_2_0, t_2_0)
    
        auto_corr = 0.5 * (psi_t_0 * np.exp(-t_0) + (psi_0_t * np.exp(t_0)).conj())

        return np.abs(auto_corr) ** 2
    \end{python}

    \input{implementation/doc/oatdccd.tex}

\subsection{Integrators and ODE Solvers}

    \input{implementation/doc/integrator.tex}

    \input{implementation/doc/RK4.tex}

    \input{implementation/doc/gauss_integrator.tex}